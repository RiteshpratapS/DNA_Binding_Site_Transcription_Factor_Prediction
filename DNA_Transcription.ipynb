{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting quadprog\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/f0/d4c8866f5d14dfa1a441439f5ce0d2680844651772129c431e78caadfe10/quadprog-0.1.7.tar.gz\n",
      "Collecting Cython (from quadprog)\n",
      "  Using cached https://files.pythonhosted.org/packages/9a/bd/d39af77b8c3a0b8881b960c467272f29a6b8c70fb425e8c665abb81e0b82/Cython-0.29.19-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Building wheels for collected packages: quadprog\n",
      "  Running setup.py bdist_wheel for quadprog ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/aims/.cache/pip/wheels/36/dd/b1/849989444c0a5930927b260663019b7da6cff864fc224c2747\n",
      "Successfully built quadprog\n",
      "Installing collected packages: Cython, quadprog\n",
      "Successfully installed Cython-0.29.19 quadprog-0.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip3 install quadprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Import Libraries and Datasets ------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been loaded\n"
     ]
    }
   ],
   "source": [
    "# Import Datasets train and test\n",
    "Train_data = pd.read_csv('Xtr.csv')\n",
    "Test_data = pd.read_csv('Xte.csv')\n",
    "\n",
    "print('Datasets have been loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label\n",
    "Label_data = pd.read_csv('Ytr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training data:  (2000, 2)\n",
      " Test data:  (1000, 2)\n",
      " label:  (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\" Training data: \",Train_data.shape)\n",
    "print (\" Test data: \",Test_data.shape)\n",
    "print (\" label: \",Label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    seq\n",
       "0     GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1     CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2     GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3     GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4     GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...\n",
       "...                                                 ...\n",
       "1995  TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...\n",
       "1996  ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...\n",
       "1997  TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...\n",
       "1998  CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...\n",
       "1999  TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = Train_data.drop(['Id'], axis = 1)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_data= Label_data.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label= np.asarray(Label_data)\n",
    "y_label = np.where(y_label ==0, -1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size] for x in range(len(sequence) - size + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data,k):\n",
    "    seq = []\n",
    "    for i in range(len(data)):\n",
    "        word = data.iloc[i]['seq']\n",
    "        word = getKmers(word, k)\n",
    "        seq.append(word)\n",
    "    names = ['txt'+str(i) for i in range(len(word))]\n",
    "    seq = np.array(seq)\n",
    "    return pd.DataFrame(data = seq,columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spe = tokenize_data(Train_data,k=3)\n",
    "test_data_spe = tokenize_data(Test_data,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_spe;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spe;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train_data_spe,test_data_spe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot(X):\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    enc.fit(X)\n",
    "    onehotlabels = enc.transform(X)\n",
    "    return onehotlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_oneHot = onehot(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "train , test = train_test_oneHot[:2000,:] , train_test_oneHot[2000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.array(Label_data['Bound'])\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_label\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6168)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the RBF kernel with parameter sigma\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    sigma: float\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return X1.dot(X2.T)\n",
    "\n",
    "def quadratic_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the quadratic kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'quadratic': quadratic_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        #if you want to add your own kernel\n",
    "        #'customer_kernel':custom_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "            \n",
    "#         if self.kernel_name == 'customer_kernel':\n",
    "#             params['parameter_1'] = kwargs.get('parameter_1', None)\n",
    "#             params['parameter_2'] = kwargs.get('parameter_2', None)\n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.01, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        # Hint the kernel matrix is computed by\n",
    "        #K=self.kernet_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        A = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] += n*self.lambd\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_ (X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)\n",
    "    \n",
    "    \n",
    "class WeightedKernelRidgeRegression(KernelRidgeRegression):\n",
    "    '''\n",
    "    Weighted Kernel Ridge Regression\n",
    "    \n",
    "    This is just used for the KernelLogistic following up\n",
    "    '''\n",
    "    def fit(self, K, y, sample_weights=None):\n",
    "\n",
    "        self.y_train = y\n",
    "        n = len(self.y_train)\n",
    "        \n",
    "        w = np.ones_like(self.y_train) if sample_weights is None else sample_weights\n",
    "        W = np.diag(np.sqrt(w))\n",
    "        \n",
    "        A = W.dot(K).dot(W)\n",
    "        A[np.diag_indices_from(A)] += self.lambd * n\n",
    "        # self.alpha = W (K + n lambda I)^-1 W y\n",
    "        self.alpha = W.dot(np.linalg.solve(A , W.dot(self.y_train)))\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class KernelLogisticRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelLogisticRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, max_iter=100, tol=1e-5):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        K = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        # IRLS\n",
    "        KRR = KernelRidgeRegression(\n",
    "            lambd=2*self.lambd,\n",
    "            kernel=self.kernel_name,\n",
    "            **self.kernel_parameters\n",
    "        )\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            m = K.dot(alpha_old)\n",
    "            w = sigmoid(m)*sigmoid(-m)\n",
    "            z = m + y/ sigmoid(y*m)\n",
    "            alpha = KRR.fit(self.X_train, z, sample_weights= w).alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol:\n",
    "                break\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        return self\n",
    "            \n",
    "    def decision_function(self, X_test):\n",
    "        K_x = self.kernel_function_(X_test, self.X_train, **self.kernel_parameters)\n",
    "        # probability of y=1(between o and 1)\n",
    "        return sigmoid(K_x.dot(self.alpha))\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas =self.decision_function(X)\n",
    "        predicted_classes = np.where(probas < 0.5, -1,1)\n",
    "        return predicted_classes\n",
    "    \n",
    "    def error(self, y_true, y_pred):\n",
    "        e = (y_true== y_pred).mean()\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split( train, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class KernelLogisticRegression_weight(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelLogisticRegression_weight, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def fit(self, X, y, max_iter=100, tol=1e-5):\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        K = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        # IRLS\n",
    "        WKRR = WeightedKernelRidgeRegression(\n",
    "            lambd=self.lambd,\n",
    "            kernel=self.kernel_name,\n",
    "            **self.kernel_parameters\n",
    "        )\n",
    "        # Initialize\n",
    "        alpha = np.zeros_like(self.y_train)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            alpha = WKRR.fit(K, z, sample_weights=w).alpha\n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol:\n",
    "                break\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        return self\n",
    "            \n",
    "    def decision_function(self, X_test):\n",
    "        K_x = self.kernel_function_(X_test, self.X_train, **self.kernel_parameters)\n",
    "        # probability of y=1(between o and 1)\n",
    "        return sigmoid(K_x.dot(self.alpha))\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas =self.decision_function(X)\n",
    "        predicted_classes = np.where(probas < 0.5, -1,1)\n",
    "        return predicted_classes\n",
    "    \n",
    "    def error(self, y_true, y_pred):\n",
    "        e = (y_true== y_pred).mean()\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-31 17:09:13,973] Finished trial#0 with value: 0.6529999999999999 with parameters: {'lambd': 6, 'sigma': 7}. Best is trial#0 with value: 0.6529999999999999.\n",
      "[I 2020-05-31 17:09:16,620] Finished trial#1 with value: 0.6529999999999999 with parameters: {'lambd': 6, 'sigma': 9}. Best is trial#0 with value: 0.6529999999999999.\n",
      "[I 2020-05-31 17:09:19,103] Finished trial#2 with value: 0.655 with parameters: {'lambd': 4, 'sigma': 6}. Best is trial#2 with value: 0.655.\n",
      "[I 2020-05-31 17:09:21,457] Finished trial#3 with value: 0.658 with parameters: {'lambd': 2, 'sigma': 6}. Best is trial#3 with value: 0.658.\n",
      "[I 2020-05-31 17:09:25,629] Finished trial#4 with value: 0.6595000000000001 with parameters: {'lambd': 0, 'sigma': 6}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:28,461] Finished trial#5 with value: 0.6535 with parameters: {'lambd': 7, 'sigma': 3}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:30,987] Finished trial#6 with value: 0.6525 with parameters: {'lambd': 5, 'sigma': 2}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:33,862] Finished trial#7 with value: 0.658 with parameters: {'lambd': 2, 'sigma': 5}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:37,513] Finished trial#8 with value: 0.6595000000000001 with parameters: {'lambd': 0, 'sigma': 1}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:40,007] Finished trial#9 with value: 0.6525 with parameters: {'lambd': 5, 'sigma': 7}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:44,031] Finished trial#10 with value: 0.6595000000000001 with parameters: {'lambd': 0, 'sigma': 10}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:47,894] Finished trial#11 with value: 0.6595000000000001 with parameters: {'lambd': 0, 'sigma': 0}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:50,559] Finished trial#12 with value: 0.658 with parameters: {'lambd': 2, 'sigma': 0}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:54,430] Finished trial#13 with value: 0.6595000000000001 with parameters: {'lambd': 0, 'sigma': 4}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:57,002] Finished trial#14 with value: 0.6519999999999999 with parameters: {'lambd': 9, 'sigma': 2}. Best is trial#4 with value: 0.6595000000000001.\n",
      "[I 2020-05-31 17:09:59,983] Finished trial#15 with value: 0.663 with parameters: {'lambd': 1, 'sigma': 8}. Best is trial#15 with value: 0.663.\n",
      "[I 2020-05-31 17:10:02,783] Finished trial#16 with value: 0.6584999999999999 with parameters: {'lambd': 3, 'sigma': 8}. Best is trial#15 with value: 0.663.\n",
      "[I 2020-05-31 17:10:05,520] Finished trial#17 with value: 0.663 with parameters: {'lambd': 1, 'sigma': 10}. Best is trial#15 with value: 0.663.\n",
      "[I 2020-05-31 17:10:08,193] Finished trial#18 with value: 0.663 with parameters: {'lambd': 1, 'sigma': 10}. Best is trial#15 with value: 0.663.\n",
      "[I 2020-05-31 17:10:11,632] Finished trial#19 with value: 0.6584999999999999 with parameters: {'lambd': 3, 'sigma': 9}. Best is trial#15 with value: 0.663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.663\n",
      "Best hyperparameters: {'lambd': 1, 'sigma': 8}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    #iris = sklearn.datasets.load_iris()\n",
    "    \n",
    "    lambd = trial.suggest_int('lambd', 1e-1, 9)\n",
    "    sigma = trial.suggest_int('sigma', 1e-1, 10)\n",
    "\n",
    "    #max_depth = int(trial.suggest_loguniform('max_depth', 1, 32))\n",
    "    \n",
    "    kernel = 'quadratic'\n",
    "\n",
    "    #sigma = 100\n",
    "#     model = KernelSVM(C=C, kernel=kernel,sigma=sigma)\n",
    "    error=[]\n",
    "    \n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(train)):\n",
    "            X_train, y_train = train[train_index], y[train_index]\n",
    "            X_valid, y_valid = train[validate_index], y[validate_index]\n",
    "            model = KernelLogisticRegression(lambd=lambd, kernel=kernel, sigma=sigma)\n",
    "            #y_pred = model.fit(X_train, np.where(y_train==0, -1,1)).predict(X_valid)\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_valid)\n",
    "            #model.error(y_pred, y_valid)\n",
    "            error.append(model.error(y_pred, y_valid))\n",
    "    \n",
    "    #clf = sklearn.ensemble.RandomForestClassifier(\n",
    "     #   n_estimators=n_estimators, max_depth=max_depth)\n",
    "    \n",
    "    return np.mean(error)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error fold 0: 0.6425\n",
      "error fold 1: 0.625\n",
      "error fold 2: 0.655\n",
      "error fold 3: 0.7125\n",
      "error fold 4: 0.68\n",
      "\n",
      "Average accuracy is : 0.663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=7)\n",
    "error = []\n",
    "\n",
    "kernel = 'quadratic'\n",
    "sigma = 8.\n",
    "lambd = 1.0\n",
    "\n",
    "for i, (train_index, validate_index) in enumerate(kfold.split(train)):\n",
    "            X_train, y_train = train[train_index], y[train_index]\n",
    "            X_valid, y_valid = train[validate_index], y[validate_index]\n",
    "            model = KernelLogisticRegression(lambd=lambd, kernel=kernel, sigma=sigma)\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_valid)\n",
    "            #model.error(y_pred, y_valid)\n",
    "            error.append(model.error(y_pred, y_valid))\n",
    "            #print(y_valid)\n",
    "            print(f'error fold {i}: {error[i]}')\n",
    "        \n",
    "print(f'\\nAverage accuracy is : {np.mean(error)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'quadratic'\n",
    "sigma = 8.\n",
    "lambd = 1.\n",
    "\n",
    "model = KernelLogisticRegression(lambd=lambd, kernel=kernel, sigma=sigma)\n",
    "y_pred = model.fit(train, y).predict(test)\n",
    "\n",
    "#print('Test error: {:.2%}'.format(model.error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=[]\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == -1:\n",
    "        submission.append(0)\n",
    "    else:submission.append(1)\n",
    "Id = np.array([i for i in range(len(y_pred))])\n",
    "sub = {'Id':Id,'Bound':submission}\n",
    "sub = pd.DataFrame(data = sub)\n",
    "sub.to_csv('model_output_klrg_675.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 77088)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## cross validation\n",
    "\n",
    "# error = []\n",
    "\n",
    "# for i, (train_index, validate_index) in enumerate(kfold.split(data_new)):\n",
    "#             X_train, y_train = data_new[train_index], y_label[train_index]\n",
    "#             X_valid, y_valid = data_new[validate_index], y_label[validate_index]\n",
    "#             model = KernelLogisticRegression(lambd=lambd, kernel=kernel, sigma=sigma)\n",
    "#             y_pred = model.fit(X_train, y_train).predict(X_valid)\n",
    "#             #model.error(y_pred, y_valid)\n",
    "#             error.append(model.error(y_pred, y_valid))\n",
    "#             #print(y_valid)\n",
    "#             print(f'error fold {i}: {error[i]}')\n",
    "        \n",
    "# print(f'\\nAverage accuracy is : {np.mean(error)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    # P = np.diag(y) @ K @ np.diag(y)\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "K = linear_kernel(X_train, X_train)\n",
    "alphas = solve_qp(*svm_dual_soft_to_qp_kernel(K, y_train, C=1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel SVM Classification\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'quadratic': quadratic_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        # 'custom_kernel': custom_kernel, # Your kernel\n",
    "    }\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, tol=1e-3):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))\n",
    "    \n",
    "    def error(self, y_true, y_pred):\n",
    "        e = (y_true== y_pred).mean()\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error fold 0: 0.6175\n",
      "error fold 1: 0.5875\n",
      "error fold 2: 0.6175\n",
      "error fold 3: 0.645\n",
      "error fold 4: 0.625\n",
      "\n",
      "Average accuracy is : 0.6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=5,shuffle=True,random_state=7)\n",
    "error = []\n",
    "\n",
    "kernel = 'linear'\n",
    "sigma = 1.\n",
    "C = 100.\n",
    "\n",
    "for i, (train_index, validate_index) in enumerate(kfold.split(train)):\n",
    "            X_train, y_train = train[train_index], y[train_index]\n",
    "            X_valid, y_valid = train[validate_index], y[validate_index]\n",
    "            model = KernelSVM(C=C, kernel=kernel, sigma=sigma)\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_valid)\n",
    "            #model.error(y_pred, y_valid)\n",
    "            error.append(model.error(y_pred, y_valid))\n",
    "            #print(y_valid)\n",
    "            print(f'error fold {i}: {error[i]}')\n",
    "        \n",
    "print(f'\\nAverage accuracy is : {np.mean(error)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inference\n",
    "\n",
    "kernel = 'linear'\n",
    "sigma = 4.\n",
    "C = 6.\n",
    "\n",
    "\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma)\n",
    "y_pred_svm = model.fit(train, y).predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "\n",
    "submission=[]\n",
    "for i in range(len(y_pred_svm)):\n",
    "    if y_pred_svm[i] == -1:\n",
    "        submission.append(0)\n",
    "    else:submission.append(1)\n",
    "Id = np.array([i for i in range(len(y_pred_svm))])\n",
    "sub = {'Id':Id,'Bound':submission}\n",
    "sub = pd.DataFrame(data = sub)\n",
    "sub.to_csv('model_output_svm_6735.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred_svm ==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-05-30 23:57:45,424] Finished trial#0 with value: 0.6185 with parameters: {'C': 5, 'sigma': 4}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:57:55,603] Finished trial#1 with value: 0.6185 with parameters: {'C': 10, 'sigma': 5}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:58:05,070] Finished trial#2 with value: 0.6185 with parameters: {'C': 2, 'sigma': 5}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:58:14,481] Finished trial#3 with value: 0.6185 with parameters: {'C': 2, 'sigma': 4}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:58:24,522] Finished trial#4 with value: 0.6185 with parameters: {'C': 8, 'sigma': 3}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:58:34,350] Finished trial#5 with value: 0.6185 with parameters: {'C': 4, 'sigma': 3}. Best is trial#0 with value: 0.6185.\n",
      "/home/aims/.local/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: Mean of empty slice.\n",
      "/home/aims/.local/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "[I 2020-05-30 23:58:43,414] Finished trial#6 with value: 0.0 with parameters: {'C': 0, 'sigma': 9}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:58:54,052] Finished trial#7 with value: 0.6185 with parameters: {'C': 5, 'sigma': 9}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:03,848] Finished trial#8 with value: 0.6185 with parameters: {'C': 1, 'sigma': 6}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:14,097] Finished trial#9 with value: 0.6185 with parameters: {'C': 6, 'sigma': 4}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:24,194] Finished trial#10 with value: 0.6185 with parameters: {'C': 11, 'sigma': 0}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:34,339] Finished trial#11 with value: 0.6185 with parameters: {'C': 11, 'sigma': 7}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:44,297] Finished trial#12 with value: 0.6185 with parameters: {'C': 8, 'sigma': 1}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-30 23:59:54,440] Finished trial#13 with value: 0.6185 with parameters: {'C': 8, 'sigma': 2}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:04,602] Finished trial#14 with value: 0.6185 with parameters: {'C': 6, 'sigma': 7}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:15,170] Finished trial#15 with value: 0.6185 with parameters: {'C': 10, 'sigma': 6}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:25,149] Finished trial#16 with value: 0.6185 with parameters: {'C': 4, 'sigma': 5}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:35,419] Finished trial#17 with value: 0.6185 with parameters: {'C': 6, 'sigma': 8}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:45,973] Finished trial#18 with value: 0.6185 with parameters: {'C': 9, 'sigma': 10}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:00:55,945] Finished trial#19 with value: 0.6185 with parameters: {'C': 4, 'sigma': 2}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:06,241] Finished trial#20 with value: 0.6185 with parameters: {'C': 7, 'sigma': 8}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:16,606] Finished trial#21 with value: 0.6185 with parameters: {'C': 9, 'sigma': 10}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:26,808] Finished trial#22 with value: 0.6185 with parameters: {'C': 4, 'sigma': 0}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:36,926] Finished trial#23 with value: 0.6185 with parameters: {'C': 5, 'sigma': 2}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:47,327] Finished trial#24 with value: 0.6185 with parameters: {'C': 7, 'sigma': 10}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:01:56,730] Finished trial#25 with value: 0.6185 with parameters: {'C': 2, 'sigma': 0}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:02:06,311] Finished trial#26 with value: 0.6185 with parameters: {'C': 3, 'sigma': 1}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:02:16,448] Finished trial#27 with value: 0.6185 with parameters: {'C': 5, 'sigma': 4}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:02:25,730] Finished trial#28 with value: 0.0 with parameters: {'C': 0, 'sigma': 1}. Best is trial#0 with value: 0.6185.\n",
      "[I 2020-05-31 00:02:35,482] Finished trial#29 with value: 0.6185 with parameters: {'C': 2, 'sigma': 1}. Best is trial#0 with value: 0.6185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6185\n",
      "Best hyperparameters: {'C': 5, 'sigma': 4}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    #iris = sklearn.datasets.load_iris()\n",
    "    \n",
    "    C = trial.suggest_int('C', 1e-2, 11)\n",
    "    sigma = trial.suggest_int('sigma', 1e-2, 10)\n",
    "\n",
    "    #max_depth = int(trial.suggest_loguniform('max_depth', 1, 32))\n",
    "    \n",
    "    kernel = 'linear'\n",
    "\n",
    "    #sigma = 100\n",
    "#     model = KernelSVM(C=C, kernel=kernel,sigma=sigma)\n",
    "    error=[]\n",
    "    \n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(train)):\n",
    "            X_train, y_train = train[train_index], y[train_index]\n",
    "            X_valid, y_valid = train[validate_index], y[validate_index]\n",
    "            model = KernelSVM(C=C, kernel=kernel, sigma=sigma)\n",
    "            y_pred = y_pred = model.fit(X_train, y_train).predict(X_valid)\n",
    "            #model.error(y_pred, y_valid)\n",
    "            error.append(model.error(y_pred, y_valid))\n",
    "    \n",
    "    #clf = sklearn.ensemble.RandomForestClassifier(\n",
    "     #   n_estimators=n_estimators, max_depth=max_depth)\n",
    "    \n",
    "    return np.mean(error)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
